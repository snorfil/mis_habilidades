{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqGCPmHQzmOZ"
      },
      "source": [
        "# Actividad evaluable UD03. Manipulación de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8ZU9YfVvuv0"
      },
      "source": [
        "# Descargar el dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "YnhpsjDovuFS"
      },
      "outputs": [],
      "source": [
        "# Libraries to handle data\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import io\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "## Carga del fichero en Python\n",
        "df_train = pd.read_csv('tiempoAustralia.csv', delimiter=',')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNA-U8FwmuY8"
      },
      "source": [
        "# Ejercicio 1. Mostrar información del dataset (1.5 puntos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQ5DoG-A085m"
      },
      "source": [
        "1.   Mostrar las primeras 10 filas del dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1n08oDUt085m",
        "outputId": "9c2af151-2d65-44e7-c3b0-a78e7e314135"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Location  MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine WindGustDir  \\\n",
            "0   Albury     13.4     22.9       0.6          NaN       NaN           W   \n",
            "1   Albury      7.4     25.1       0.0          NaN       NaN         WNW   \n",
            "2   Albury     12.9     25.7       0.0          NaN       NaN         WSW   \n",
            "3   Albury      9.2     28.0       0.0          NaN       NaN          NE   \n",
            "4   Albury     17.5     32.3       1.0          NaN       NaN           W   \n",
            "5   Albury     14.6     29.7       0.2          NaN       NaN         WNW   \n",
            "6   Albury     14.3     25.0       0.0          NaN       NaN           W   \n",
            "7   Albury      7.7     26.7       0.0          NaN       NaN           W   \n",
            "8   Albury      9.7     31.9       0.0          NaN       NaN         NNW   \n",
            "9   Albury     13.1     30.1       1.4          NaN       NaN           W   \n",
            "\n",
            "   WindGustSpeed WindDir9am WindDir3pm  ...  Humidity3pm  Pressure9am  \\\n",
            "0           44.0          W        WNW  ...         22.0       1007.7   \n",
            "1           44.0        NNW        WSW  ...         25.0       1010.6   \n",
            "2           46.0          W        WSW  ...         30.0       1007.6   \n",
            "3           24.0         SE          E  ...         16.0       1017.6   \n",
            "4           41.0        ENE         NW  ...         33.0       1010.8   \n",
            "5           56.0          W          W  ...         23.0       1009.2   \n",
            "6           50.0         SW          W  ...         19.0       1009.6   \n",
            "7           35.0        SSE          W  ...         19.0       1013.4   \n",
            "8           80.0         SE         NW  ...          9.0       1008.9   \n",
            "9           28.0          S        SSE  ...         27.0       1007.0   \n",
            "\n",
            "   Pressure3pm  Cloud9am  Cloud3pm  Temp9am  Temp3pm  RainToday  RainTomorrow  \\\n",
            "0       1007.1       8.0       NaN     16.9     21.8         No            No   \n",
            "1       1007.8       NaN       NaN     17.2     24.3         No            No   \n",
            "2       1008.7       NaN       2.0     21.0     23.2         No            No   \n",
            "3       1012.8       NaN       NaN     18.1     26.5         No            No   \n",
            "4       1006.0       7.0       8.0     17.8     29.7         No            No   \n",
            "5       1005.4       NaN       NaN     20.6     28.9         No            No   \n",
            "6       1008.2       1.0       NaN     18.1     24.6         No            No   \n",
            "7       1010.1       NaN       NaN     16.3     25.5         No            No   \n",
            "8       1003.6       NaN       NaN     18.3     30.2         No           Yes   \n",
            "9       1005.7       NaN       NaN     20.1     28.2        Yes            No   \n",
            "\n",
            "   Month  \n",
            "0     12  \n",
            "1     12  \n",
            "2     12  \n",
            "3     12  \n",
            "4     12  \n",
            "5     12  \n",
            "6     12  \n",
            "7     12  \n",
            "8     12  \n",
            "9     12  \n",
            "\n",
            "[10 rows x 23 columns]\n"
          ]
        }
      ],
      "source": [
        "print(df_train.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOkp6t8-085n"
      },
      "source": [
        "2.   Mostrar información básica del dataframe con las columnas que lo componen, número valores no nulos, número valores nulos y tipo de datos de la columna."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTtzR8qG085n",
        "outputId": "3a0d796d-49bb-4193-87d0-055c9825fbdc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 145460 entries, 0 to 145459\n",
            "Data columns (total 23 columns):\n",
            " #   Column         Non-Null Count   Dtype  \n",
            "---  ------         --------------   -----  \n",
            " 0   Location       145460 non-null  object \n",
            " 1   MinTemp        143975 non-null  float64\n",
            " 2   MaxTemp        144199 non-null  float64\n",
            " 3   Rainfall       142199 non-null  float64\n",
            " 4   Evaporation    82670 non-null   float64\n",
            " 5   Sunshine       75625 non-null   float64\n",
            " 6   WindGustDir    135134 non-null  object \n",
            " 7   WindGustSpeed  135197 non-null  float64\n",
            " 8   WindDir9am     134894 non-null  object \n",
            " 9   WindDir3pm     141232 non-null  object \n",
            " 10  WindSpeed9am   143693 non-null  float64\n",
            " 11  WindSpeed3pm   142398 non-null  float64\n",
            " 12  Humidity9am    142806 non-null  float64\n",
            " 13  Humidity3pm    140953 non-null  float64\n",
            " 14  Pressure9am    130395 non-null  float64\n",
            " 15  Pressure3pm    130432 non-null  float64\n",
            " 16  Cloud9am       89572 non-null   float64\n",
            " 17  Cloud3pm       86102 non-null   float64\n",
            " 18  Temp9am        143693 non-null  float64\n",
            " 19  Temp3pm        141851 non-null  float64\n",
            " 20  RainToday      142199 non-null  object \n",
            " 21  RainTomorrow   142193 non-null  object \n",
            " 22  Month          145460 non-null  int64  \n",
            "dtypes: float64(16), int64(1), object(6)\n",
            "memory usage: 25.5+ MB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# Mostrar información básica del dataframe\n",
        "print(df_train.info())\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvv9jmVd085n"
      },
      "source": [
        "3.   Mostrar información básica de cada columna (numero ocurrencias, media, desviación típica, valor mínimo, el valor máximo, y los límites de los cuartiles 25%, 50% y 75%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NI_Sxp8085n",
        "outputId": "4be9abb6-3d8f-4f16-faf7-881801a5a484"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        Location        MinTemp        MaxTemp       Rainfall   Evaporation  \\\n",
            "count     145460  143975.000000  144199.000000  142199.000000  82670.000000   \n",
            "unique        49            NaN            NaN            NaN           NaN   \n",
            "top     Canberra            NaN            NaN            NaN           NaN   \n",
            "freq        3436            NaN            NaN            NaN           NaN   \n",
            "mean         NaN      12.194034      23.221348       2.360918      5.468232   \n",
            "std          NaN       6.398495       7.119049       8.478060      4.193704   \n",
            "min          NaN      -8.500000      -4.800000       0.000000      0.000000   \n",
            "25%          NaN       7.600000      17.900000       0.000000      2.600000   \n",
            "50%          NaN      12.000000      22.600000       0.000000      4.800000   \n",
            "75%          NaN      16.900000      28.200000       0.800000      7.400000   \n",
            "max          NaN      33.900000      48.100000     371.000000    145.000000   \n",
            "\n",
            "            Sunshine WindGustDir  WindGustSpeed WindDir9am WindDir3pm  ...  \\\n",
            "count   75625.000000      135134  135197.000000     134894     141232  ...   \n",
            "unique           NaN          16            NaN         16         16  ...   \n",
            "top              NaN           W            NaN          N         SE  ...   \n",
            "freq             NaN        9915            NaN      11758      10838  ...   \n",
            "mean        7.611178         NaN      40.035230        NaN        NaN  ...   \n",
            "std         3.785483         NaN      13.607062        NaN        NaN  ...   \n",
            "min         0.000000         NaN       6.000000        NaN        NaN  ...   \n",
            "25%         4.800000         NaN      31.000000        NaN        NaN  ...   \n",
            "50%         8.400000         NaN      39.000000        NaN        NaN  ...   \n",
            "75%        10.600000         NaN      48.000000        NaN        NaN  ...   \n",
            "max        14.500000         NaN     135.000000        NaN        NaN  ...   \n",
            "\n",
            "          Humidity3pm   Pressure9am    Pressure3pm      Cloud9am  \\\n",
            "count   140953.000000  130395.00000  130432.000000  89572.000000   \n",
            "unique            NaN           NaN            NaN           NaN   \n",
            "top               NaN           NaN            NaN           NaN   \n",
            "freq              NaN           NaN            NaN           NaN   \n",
            "mean        51.539116    1017.64994    1015.255889      4.447461   \n",
            "std         20.795902       7.10653       7.037414      2.887159   \n",
            "min          0.000000     980.50000     977.100000      0.000000   \n",
            "25%         37.000000    1012.90000    1010.400000      1.000000   \n",
            "50%         52.000000    1017.60000    1015.200000      5.000000   \n",
            "75%         66.000000    1022.40000    1020.000000      7.000000   \n",
            "max        100.000000    1041.00000    1039.600000      9.000000   \n",
            "\n",
            "            Cloud3pm        Temp9am       Temp3pm  RainToday  RainTomorrow  \\\n",
            "count   86102.000000  143693.000000  141851.00000     142199        142193   \n",
            "unique           NaN            NaN           NaN          2             2   \n",
            "top              NaN            NaN           NaN         No            No   \n",
            "freq             NaN            NaN           NaN     110319        110316   \n",
            "mean        4.509930      16.990631      21.68339        NaN           NaN   \n",
            "std         2.720357       6.488753       6.93665        NaN           NaN   \n",
            "min         0.000000      -7.200000      -5.40000        NaN           NaN   \n",
            "25%         2.000000      12.300000      16.60000        NaN           NaN   \n",
            "50%         5.000000      16.700000      21.10000        NaN           NaN   \n",
            "75%         7.000000      21.600000      26.40000        NaN           NaN   \n",
            "max         9.000000      40.200000      46.70000        NaN           NaN   \n",
            "\n",
            "                Month  \n",
            "count   145460.000000  \n",
            "unique            NaN  \n",
            "top               NaN  \n",
            "freq              NaN  \n",
            "mean         6.399615  \n",
            "std          3.427262  \n",
            "min          1.000000  \n",
            "25%          3.000000  \n",
            "50%          6.000000  \n",
            "75%          9.000000  \n",
            "max         12.000000  \n",
            "\n",
            "[11 rows x 23 columns]\n"
          ]
        }
      ],
      "source": [
        "# Mostrar información descriptiva básica de cada columna\n",
        "print(df_train.describe(include='all'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeQYERVV085n"
      },
      "source": [
        "4.   Mostrar una lista con el nombre de columnas que son categóricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iqPTUv1085n",
        "outputId": "3fb76c12-3615-4386-96d9-c6e4ecee5073"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columnas categóricas: ['Location', 'WindGustDir', 'WindDir9am', 'WindDir3pm', 'RainToday', 'RainTomorrow']\n"
          ]
        }
      ],
      "source": [
        "# Identificar columnas categóricas\n",
        "categorical_columns = df_train.select_dtypes(include=['object']).columns.tolist()\n",
        "print(\"Columnas categóricas:\", categorical_columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMH6sBqrN3Jx"
      },
      "source": [
        "# Ejercicio 2. Trabajo sobre ocurrencias (1.5 puntos)\n",
        "\n",
        "1. Muestra el número de ocurrencias de los diferentes valores de 'RainTomorrow'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "NRtoyaUTzOQL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4225bc3-fcbd-40e4-bee2-b22cc4d135a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RainTomorrow\n",
            "No     110316\n",
            "Yes     31877\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Contar ocurrencias de los diferentes valores de 'RainTomorrow'\n",
        "print(df_train['RainTomorrow'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wq_EHVsiEUN"
      },
      "source": [
        "2. Modifica el dataframe balanceando las ocurrencias de 'RainTomorrow' al valor intermedio del que más tiene y el que menos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "xChkoJVB085o"
      },
      "outputs": [],
      "source": [
        "# Balancear las ocurrencias de 'RainTomorrow'\n",
        "class_counts = df_train['RainTomorrow'].value_counts()\n",
        "min_count = min(class_counts)\n",
        "\n",
        "# Tomar una muestra balanceada de cada clase\n",
        "balanced_df = pd.concat([\n",
        "    df_train[df_train['RainTomorrow'] == 'Yes'].sample(min_count),\n",
        "    df_train[df_train['RainTomorrow'] == 'No'].sample(min_count)\n",
        "])\n",
        "\n",
        "# Mezclar aleatoriamente el dataframe balanceado\n",
        "balanced_df = shuffle(balanced_df)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import resample\n",
        "\n",
        "# Balancear las ocurrencias de 'RainTomorrow'\n",
        "df_majority = df_train[df_train['RainTomorrow'] == 'No']\n",
        "df_minority = df_train[df_train['RainTomorrow'] == 'Yes']\n",
        "\n",
        "df_minority_upsampled = resample(df_minority,\n",
        "                                 replace=True,\n",
        "                                 n_samples=len(df_majority),\n",
        "                                 random_state=123)\n",
        "\n",
        "balanced_df = pd.concat([df_majority, df_minority_upsampled])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQAROekd7y21",
        "outputId": "121cbf90-b239-4644-a4bc-c883de350e0c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RainTomorrow\n",
            "No     110316\n",
            "Yes    110316\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFTdmST3085o"
      },
      "source": [
        "3. Muestra el número de ocurrencias de los diferentes valores de 'RainTomorrow' para comprobar que el dataset está balanceado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lql9ugkh085o",
        "outputId": "dae2c034-5de6-45d3-8d46-86600a4694e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RainTomorrow\n",
            "No     110316\n",
            "Yes    110316\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(balanced_df['RainTomorrow'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAY2B2kwmS5_"
      },
      "source": [
        "# Ejercicio 3. Tratamiento de valores nulos (1 punto)\n",
        "\n",
        "1. Identifica y elimina del dataset aquellas columnas que tengan más del 40% de sus ocurrencias con valores nulos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "v4719UXj5X7n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9adb7caf-964d-435c-d791-022840497b0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "88252.8\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 220632 entries, 0 to 27220\n",
            "Data columns (total 23 columns):\n",
            " #   Column         Non-Null Count   Dtype  \n",
            "---  ------         --------------   -----  \n",
            " 0   Location       220632 non-null  object \n",
            " 1   MinTemp        219550 non-null  float64\n",
            " 2   MaxTemp        220161 non-null  float64\n",
            " 3   Rainfall       217508 non-null  float64\n",
            " 4   Evaporation    125221 non-null  float64\n",
            " 5   Sunshine       115801 non-null  float64\n",
            " 6   WindGustDir    205141 non-null  object \n",
            " 7   WindGustSpeed  205278 non-null  float64\n",
            " 8   WindDir9am     205904 non-null  object \n",
            " 9   WindDir3pm     214192 non-null  object \n",
            " 10  WindSpeed9am   218426 non-null  float64\n",
            " 11  WindSpeed3pm   216279 non-null  float64\n",
            " 12  Humidity9am    217461 non-null  float64\n",
            " 13  Humidity3pm    214601 non-null  float64\n",
            " 14  Pressure9am    198904 non-null  float64\n",
            " 15  Pressure3pm    198886 non-null  float64\n",
            " 16  Cloud9am       139293 non-null  float64\n",
            " 17  Cloud3pm       135018 non-null  float64\n",
            " 18  Temp9am        218979 non-null  float64\n",
            " 19  Temp3pm        216074 non-null  float64\n",
            " 20  RainToday      217508 non-null  object \n",
            " 21  RainTomorrow   220632 non-null  object \n",
            " 22  Month          220632 non-null  int64  \n",
            "dtypes: float64(16), int64(1), object(6)\n",
            "memory usage: 40.4+ MB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# Eliminar columnas con más del 40% de valores nulos\n",
        "umbral = len(balanced_df) * 0.4\n",
        "print(umbral)\n",
        "\n",
        "filtered_df = balanced_df.dropna(thresh=umbral, axis=1)\n",
        "print(filtered_df.info())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHMBizBG085p"
      },
      "source": [
        "2. Del resto de columnas con valores nulos. Completa dichos valores con la última observación válida."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "3-jl2lwlbys8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2161153c-4617-482d-b010-edfffcdb981e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 220632 entries, 0 to 27220\n",
            "Data columns (total 23 columns):\n",
            " #   Column         Non-Null Count   Dtype  \n",
            "---  ------         --------------   -----  \n",
            " 0   Location       220632 non-null  object \n",
            " 1   MinTemp        220632 non-null  float64\n",
            " 2   MaxTemp        220632 non-null  float64\n",
            " 3   Rainfall       220632 non-null  float64\n",
            " 4   Evaporation    215894 non-null  float64\n",
            " 5   Sunshine       215894 non-null  float64\n",
            " 6   WindGustDir    220632 non-null  object \n",
            " 7   WindGustSpeed  220632 non-null  float64\n",
            " 8   WindDir9am     220632 non-null  object \n",
            " 9   WindDir3pm     220632 non-null  object \n",
            " 10  WindSpeed9am   220632 non-null  float64\n",
            " 11  WindSpeed3pm   220632 non-null  float64\n",
            " 12  Humidity9am    220632 non-null  float64\n",
            " 13  Humidity3pm    220632 non-null  float64\n",
            " 14  Pressure9am    220632 non-null  float64\n",
            " 15  Pressure3pm    220632 non-null  float64\n",
            " 16  Cloud9am       220632 non-null  float64\n",
            " 17  Cloud3pm       220630 non-null  float64\n",
            " 18  Temp9am        220632 non-null  float64\n",
            " 19  Temp3pm        220632 non-null  float64\n",
            " 20  RainToday      220632 non-null  object \n",
            " 21  RainTomorrow   220632 non-null  object \n",
            " 22  Month          220632 non-null  int64  \n",
            "dtypes: float64(16), int64(1), object(6)\n",
            "memory usage: 40.4+ MB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# Rellenar valores nulos con la última observación válida\n",
        "filled_df = filtered_df.fillna(method='ffill')\n",
        "print(filled_df.info())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7-dOoWAiwCu"
      },
      "source": [
        "# Ejercicio 4. Transformar variables categóricas a numéricas (2.5 puntos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMUcGJN4085p"
      },
      "source": [
        "1. Utiliza LabelEncoder para transformar las variables categóricas \"RainToday\" y \"RainTomorrow\", asegurandote de que el mapeo va a ser exactamente igual para las dos columnas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "hfI7RmA8jNEy"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Transformar 'RainToday' y 'RainTomorrow' usando el mismo mapeo\n",
        "le = LabelEncoder()\n",
        "filled_df['RainToday'] = le.fit_transform(filled_df['RainToday'])\n",
        "filled_df['RainTomorrow'] = le.transform(filled_df['RainTomorrow'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtNOhEIA085p"
      },
      "source": [
        "2. Utiliza one_hot para transformar en numérica la columna Location, ¿cuántas columnas nuevas se han creado? ¿Son las mismas que el número diferente de valores en la columna Location? Posteriormente, elimina la columna Location."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "BJG8LIGT085q",
        "outputId": "16a5e509-7d25-4cf1-8b22-0b6674a69ba7"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'Location'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3653\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3654\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Location'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-5ddf75703b61>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Transformar la columna Location usando one-hot encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlocation_dummies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilled_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Location'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Location'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mfilled_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfilled_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation_dummies\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfilled_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilled_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Location'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Se han creado {location_dummies.shape[1]} nuevas columnas.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3761\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3762\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3763\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3654\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3655\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3656\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3657\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Location'"
          ]
        }
      ],
      "source": [
        "# Transformar la columna Location usando one-hot encoding\n",
        "location_dummies = pd.get_dummies(filled_df['Location'], prefix='Location')\n",
        "filled_df = pd.concat([filled_df, location_dummies], axis=1)\n",
        "filled_df = filled_df.drop(['Location'], axis=1)\n",
        "print(f\"Se han creado {location_dummies.shape[1]} nuevas columnas.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Transformar la columna Location usando one-hot encoding\n",
        "onehot = OneHotEncoder(drop='first', sparse=False)\n",
        "location_encoded = onehot.fit_transform(filled_df[['Location']])\n",
        "location_encoded_df = pd.DataFrame(location_encoded, columns=onehot.get_feature_names_out(['Location']))\n",
        "\n",
        "# Añadir las columnas one-hot codificadas y eliminar la columna original\n",
        "imputed_df = filled_df.drop('Location', axis=1)\n",
        "imputed_df = pd.concat([filled_df, location_encoded_df], axis=1)\n",
        "print(f\"Se han creado {location_encoded_df.shape[1]} nuevas columnas.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "id": "uMzyVTmF8b5m",
        "outputId": "5205a295-13e3-4570-abfd-cd7c484ea071"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidIndexError",
          "evalue": "Reindexing only valid with uniquely valued Index objects",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-5490789969ba>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Añadir las columnas one-hot codificadas y eliminar la columna original\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mimputed_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilled_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Location'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mimputed_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfilled_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation_encoded_df\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Se han creado {location_encoded_df.shape[1]} nuevas columnas.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    383\u001b[0m     )\n\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    610\u001b[0m                     \u001b[0mobj_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m                         \u001b[0mindexers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m                 \u001b[0mmgrs_indexers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_indexer\u001b[0;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[1;32m   3730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3731\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_as_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3732\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_requires_unique_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3734\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidIndexError\u001b[0m: Reindexing only valid with uniquely valued Index objects"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUye23FX085q"
      },
      "source": [
        "3. Analiza el resto de columnas categóricas y utiliza LabelEncoder para realizar el mismo mapeo. Puedes utilizar cualquiera de las columnas categóricas para ajustar LabelEncoder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "BD31ICBm085q"
      },
      "outputs": [],
      "source": [
        "# Transformar el resto de las columnas categóricas\n",
        "for col in categorical_columns:\n",
        "    if col in filled_df.columns and col not in ['RainToday', 'RainTomorrow']:\n",
        "        filled_df[col] = le.fit_transform(filled_df[col])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYMizPNaieJa"
      },
      "source": [
        "# Ejercicio 5. Normalizacion (1 punto)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46S7fs97085q"
      },
      "source": [
        "1.  Normaliza el dataframe completo excepto RainTomorrow y RainToday."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "6g7zmL5mzbOG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "outputId": "c3cc52fc-3737-4fee-c582-4e32f8331d67"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "could not convert string to float: 'WNW'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-3f0b8ddd3b8e>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcols_to_normalize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimputed_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdifference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'RainToday'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'RainTomorrow'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mimputed_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcols_to_normalize\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimputed_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcols_to_normalize\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    876\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    879\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0mfirst_pass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"n_samples_seen_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m         X = self._validate_data(\n\u001b[0m\u001b[1;32m    467\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m             \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfirst_pass\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    877\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m                 raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"numpy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"numpy.array_api\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;31m# Use NumPy API to support order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1996\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1997\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1998\u001b[0;31m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1999\u001b[0m         if (\n\u001b[1;32m   2000\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'WNW'"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Normalizar el dataframe excepto las columnas 'RainToday' y 'RainTomorrow'\n",
        "cols_to_normalize = imputed_df.columns.difference(['RainToday', 'RainTomorrow'])\n",
        "scaler = MinMaxScaler()\n",
        "imputed_df[cols_to_normalize] = scaler.fit_transform(imputed_df[cols_to_normalize])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyBVsvHP085q"
      },
      "source": [
        "2. Comprueba que todos los valores se encuentran entre 1 y 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PmFe_jvN085r"
      },
      "outputs": [],
      "source": [
        "# Comprobar que todos los valores están entre 0 y 1\n",
        "print(filled_df[cols_to_normalize].describe().loc[['min', 'max']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xH0tcYJ085r"
      },
      "source": [
        "# Ejercicio 6. División del dataset (2.5 puntos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hausYhpf085r"
      },
      "source": [
        "1. Divide el dataset en 4 grupos, el primero será el conjunto de entrenamiento y tendrá el 75% de las ocurrencias, el segundo será el conjunto de test con un 15% de las ocurrencias, el tercero será el conjunto de validación y tendrá el 5% de las ocurrencias y finalmente, el de ejemplos tendrá un 5% de las ocurrencias."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKbu28Cy085r",
        "outputId": "82b28ccf-90d0-46ed-c7aa-c6ab72ecf620"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamaño del conjunto de entrenamiento: 17604\n",
            "Tamaño del conjunto de test: 3520\n",
            "Tamaño del conjunto de validación: 1173\n",
            "Tamaño del conjunto de ejemplos: 1175\n"
          ]
        }
      ],
      "source": [
        "# División del dataset\n",
        "train_size = int(0.75 * len(filled_df))\n",
        "test_size = int(0.15 * len(filled_df))\n",
        "validation_size = int(0.05 * len(filled_df))\n",
        "\n",
        "train_df = filled_df[:train_size]\n",
        "test_df = filled_df[train_size:train_size+test_size]\n",
        "validation_df = filled_df[train_size+test_size:train_size+test_size+validation_size]\n",
        "examples_df = filled_df[train_size+test_size+validation_size:]\n",
        "\n",
        "# Comprobar los tamaños\n",
        "print(f\"Tamaño del conjunto de entrenamiento: {len(train_df)}\")\n",
        "print(f\"Tamaño del conjunto de test: {len(test_df)}\")\n",
        "print(f\"Tamaño del conjunto de validación: {len(validation_df)}\")\n",
        "print(f\"Tamaño del conjunto de ejemplos: {len(examples_df)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# División del dataset\n",
        "train_df, temp_df = train_test_split(imputed_df, test_size=0.25, random_state=42)\n",
        "test_df, val_examples_df = train_test_split(temp_df, test_size=0.2, random_state=42)\n",
        "validation_df, examples_df = train_test_split(val_examples_df, test_size=0.5, random_state=42)\n",
        "\n"
      ],
      "metadata": {
        "id": "Op2APxqL-gix"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmK8kO-9085r"
      },
      "source": [
        "2. Comprueba que los tamaños coinciden con lo especificado en el anterior ejercicio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14VckUSr085r",
        "outputId": "88316551-bb69-428f-ddc5-d19931890970"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamaño del conjunto de entrenamiento: 165474\n",
            "Tamaño del conjunto de test: 44126\n",
            "Tamaño del conjunto de validación: 5516\n",
            "Tamaño del conjunto de ejemplos: 5516\n"
          ]
        }
      ],
      "source": [
        "# Comprobar los tamaños\n",
        "print(f\"Tamaño del conjunto de entrenamiento: {len(train_df)}\")\n",
        "print(f\"Tamaño del conjunto de test: {len(test_df)}\")\n",
        "print(f\"Tamaño del conjunto de validación: {len(validation_df)}\")\n",
        "print(f\"Tamaño del conjunto de ejemplos: {len(examples_df)}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}