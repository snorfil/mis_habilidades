{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBmeRj3pi_kb"
      },
      "source": [
        "# Manipulación de datos (preprocesamiento)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIjx59KSTN0o"
      },
      "source": [
        "**Ejercicio 1.** Descarga del aula virtual el dataset y crea un dataframe llamado df_diabetes para trabajar con el.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "btICyqiWc8kY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qv0n3DxIbUGG"
      },
      "source": [
        "**Ejercicio 2.** Obten una lista de todas las columnas que tiene."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3SsXGiIgTOlw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Cargar los datos desde un archivo CSV\n",
        "file_path = 'data.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Obtener la lista de todas las columnas\n",
        "columnas = data.columns.tolist()\n",
        "\n",
        "# Imprimir la lista de columnas\n",
        "print(\"Lista de columnas:\", columnas)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yj3LWIuibUGG"
      },
      "source": [
        "**Ejercicio 3.** Identifica qué columas con categóricas y cuales numéricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o0g_ORtZbUGH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Cargar los datos desde un archivo CSV\n",
        "file_path = 'data.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Identificar tipos de datos\n",
        "tipos_de_datos = data.dtypes\n",
        "\n",
        "# Separar columnas categóricas y numéricas\n",
        "columnas_categoricas = tipos_de_datos[tipos_de_datos == 'object'].index.tolist()\n",
        "columnas_numericas = tipos_de_datos[tipos_de_datos != 'object'].index.tolist()\n",
        "\n",
        "# Imprimir las columnas categóricas y numéricas\n",
        "print(\"Columnas categóricas:\", columnas_categoricas)\n",
        "print(\"Columnas numéricas:\", columnas_numericas)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbwbUo7kbUGH"
      },
      "source": [
        "**Ejercicio 4.** De la lista de columnas categóricas identifica de qué tipo son: ordinales o nominales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JyBXBjHibUGH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Cargar los datos desde un archivo CSV\n",
        "file_path = 'data.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Identificar columnas categóricas (suponiendo que ya hemos hecho esto en el ejercicio anterior)\n",
        "columnas_categoricas = data.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "# Diccionario para almacenar el tipo de cada columna categórica\n",
        "columnas_categoricas_tipos = {}\n",
        "\n",
        "# Manualmente identificar si las columnas son nominales u ordinales\n",
        "# Aquí se debe conocer el contexto de los datos, esto es solo un ejemplo\n",
        "for col in columnas_categoricas:\n",
        "    # Ejemplo de categorías ordinales\n",
        "    if col in ['education_level', 'rating', 'experience_years']:\n",
        "        columnas_categoricas_tipos[col] = 'ordinal'\n",
        "    # Ejemplo de categorías nominales\n",
        "    elif col in ['gender', 'color', 'country']:\n",
        "        columnas_categoricas_tipos[col] = 'nominal'\n",
        "    else:\n",
        "        columnas_categoricas_tipos[col] = 'unknown'  # Si no estamos seguros, lo marcamos como desconocido\n",
        "\n",
        "# Imprimir los resultados\n",
        "for col, tipo in columnas_categoricas_tipos.items():\n",
        "    print(f\"Columna: {col}, Tipo: {tipo}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rp7jSKGSbUGH"
      },
      "source": [
        "**Ejercicio 5.** Estamos interesados en transformar las columnas categóricas a numéricas. Implementa dicha transformación teniendo en cuenta que 'smoking_history' es considerado como una variable categórica ordinal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "twKPg1K2bUGI"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
        "\n",
        "# Crear el encoder para las columnas ordinales\n",
        "ordinal_encoder = OrdinalEncoder()\n",
        "\n",
        "# Aplicar el encoder a las columnas ordinales\n",
        "data[columnas_ordinales] = ordinal_encoder.fit_transform(data[columnas_ordinales])\n",
        "\n",
        "# Crear el encoder para las columnas nominales\n",
        "onehot_encoder = OneHotEncoder(drop='first', sparse=False)\n",
        "\n",
        "# Aplicar el encoder a las columnas nominales\n",
        "encoded_nominales = onehot_encoder.fit_transform(data[columnas_nominales])\n",
        "\n",
        "# Crear un DataFrame con las columnas codificadas\n",
        "encoded_nominales_df = pd.DataFrame(encoded_nominales, columns=onehot_encoder.get_feature_names_out(columnas_nominales))\n",
        "\n",
        "# Restablecer el índice para concatenar correctamente\n",
        "data.reset_index(drop=True, inplace=True)\n",
        "encoded_nominales_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Concatenar los DataFrames original y codificado\n",
        "data = pd.concat([data.drop(columns=columnas_nominales), encoded_nominales_df], axis=1)\n",
        "\n",
        "# Imprimir el DataFrame transformado\n",
        "print(data.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utP-KB8EbUGI"
      },
      "source": [
        "**Ejercicio 6.** Elimina aquellas ocurrencias en las que el genero no sea ni femenino ni masculino. Antes de eliminarlas identifica qué porcentaje de todas las ocurrencias vas a eliminar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81sWivj4bUGI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Cargar los datos desde un archivo CSV\n",
        "file_path = 'data.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Mostrar las primeras filas del DataFrame para verificar\n",
        "print(data.head())\n",
        "\n",
        "# Identificar ocurrencias donde el género no es ni 'female' ni 'male'\n",
        "invalid_gender_mask = ~data['gender'].isin(['female', 'male'])\n",
        "\n",
        "# Calcular el porcentaje de ocurrencias a eliminar\n",
        "num_invalid = invalid_gender_mask.sum()\n",
        "total_rows = len(data)\n",
        "percentage_invalid = (num_invalid / total_rows) * 100\n",
        "\n",
        "print(f\"Porcentaje de ocurrencias a eliminar: {percentage_invalid:.2f}%\")\n",
        "\n",
        "# Eliminar las filas con género inválido\n",
        "data_cleaned = data[~invalid_gender_mask]\n",
        "\n",
        "# Mostrar las primeras filas del DataFrame limpio para verificar\n",
        "print(data_cleaned.head())\n",
        "print(f\"Total de filas después de la limpieza: {len(data_cleaned)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pamzSGFjbUGI"
      },
      "source": [
        "**Ejercicio 7.** La columnas a predecir se llama diabetes, identifica qué valores diferentes toma."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4wbULBPUsgJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Cargar los datos desde un archivo CSV\n",
        "file_path = 'data.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Identificar los valores únicos de la columna 'diabetes'\n",
        "valores_unicos_diabetes = data['diabetes'].unique()\n",
        "\n",
        "# Imprimir los valores únicos\n",
        "print(\"Valores únicos de la columna 'diabetes':\", valores_unicos_diabetes)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvlBWrpxfNZn"
      },
      "source": [
        "**Ejercicio 8.** Identifica si el dataset está balanceado de acuerdo al número de personas con género masculino y femenino. Consideraremos que está balanceado si ninguno de ellos supera el 60% del total de ocurrencias. **No hace falta que lo balancees.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uj5dYnW7fRDl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ep56GLk3f_oS"
      },
      "source": [
        "**Ejercicio 9.** Identifica si el dataset está balanceado de acuerdo a la variable a predecir."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YUqZjS8pgJpa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sqk8_uIjbUGJ"
      },
      "source": [
        "**Ejercicio 10.** Balancea el dataset de acuerdo a la variable a predecir. El balanceamiento lo debes hacer de tal forma que el número de ocurrencias sea un valor intermedio entre el que más tiene y el que menos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2WWWp9YXbUGJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z6CqyRZobUGJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sePcywd-lL5-"
      },
      "source": [
        "**Ejercicio 11.** Identifica aquellas columnas que tengan más del 3% de sus ocurrencias con valores nulos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6y6z2strQL6n"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mAHq1C_mbUGK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLc1TuSNbUGK"
      },
      "source": [
        "**Ejercicio 12.** Completa los valores nulos de la columna smoking_history con el valor 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4nqstYtbUGK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4Vh_wSvbUGK"
      },
      "source": [
        "**Ejercicio 13.** Mostrar aquellas ocurrencias que la hipertension sea 0, que el bmi se encuentre entre 7 y 103, que el blood_glucose_level se encuentre entre 100 y 159, y que sea hombre de menos de 30 años que sufra de alguna enfermedad del corazón.\n",
        "\n",
        "OJO. Únicamente muestralas, no hace falta que modifiques el dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NePoSR7bbUGK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Qi_Ax6zbUGK"
      },
      "source": [
        "**Ejercicio 14**. Divide el dataset en 3 grupos, el primero será el conjunto de entrenamiento y tendrá el 75% de las ocurrencias, el segundo será el conjunto de test con un 15% de las ocurrencias y finalmente el último con un 10% será el conjunto de validación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4dP-UeSkbUGK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImfW6utObUGL"
      },
      "source": [
        "**Ejercicio 15**. Comprobar que los tamaños de los datasets concuerdan con el enunciado que he indicado anteriormente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w1L-9YxjbUGL"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "-wVJm3ZycO5X",
        "QvlBWrpxfNZn",
        "0akOwJPPfjMd",
        "trQrtkSDfz9R",
        "ep56GLk3f_oS",
        "9ftSVtzug0Fp"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}